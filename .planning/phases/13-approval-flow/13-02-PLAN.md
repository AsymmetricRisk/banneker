---
phase: 13-approval-flow
plan: 02
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - templates/commands/banneker-approve.md
  - lib/approval-prompts.js
autonomous: true

must_haves:
  truths:
    - "User can approve individual decisions (per-decision granularity)"
    - "User can edit a decision before approving it"
    - "User can reject decisions with a reason"
    - "Edit opens decision in $EDITOR as JSON with instructional comments"
  artifacts:
    - path: "templates/commands/banneker-approve.md"
      provides: "Approval command orchestrator"
      contains: "/banneker:approve"
    - path: "lib/approval-prompts.js"
      provides: "Interactive prompts for approval workflow"
      exports: ["promptForBatchSelection", "promptForRejectionReason", "editDecisionInEditor"]
  key_links:
    - from: "templates/commands/banneker-approve.md"
      to: "lib/approval.js"
      via: "spawned agent uses merge functions"
      pattern: "mergeApprovedDecisions|logRejectedDecisions"
    - from: "lib/approval-prompts.js"
      to: "$EDITOR"
      via: "child_process spawn"
      pattern: "spawn.*EDITOR"
---

<objective>
Create the approval command orchestrator and interactive prompts that enable per-decision approval with edit-before-approve capability.

Purpose: Enable users to review AI-generated decisions with granular control - approve individually, edit before accepting, or reject with logged reasons. This fulfills APPROVE-01 (explicit approval), APPROVE-02 (per-decision), and APPROVE-03 (edit-before-approve).

Output: Command orchestrator (banneker-approve.md) and prompt library (approval-prompts.js) following established Banneker patterns.
</objective>

<execution_context>
@/home/daniel/.claude/get-shit-done/workflows/execute-plan.md
@/home/daniel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-approval-flow/13-RESEARCH.md
@.planning/phases/13-approval-flow/13-01-SUMMARY.md

# Existing patterns to follow
@lib/prompts.js
@templates/commands/banneker-engineer.md
@templates/config/engineering-catalog.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create approval-prompts.js with interactive workflow functions</name>
  <files>lib/approval-prompts.js</files>
  <action>
Create lib/approval-prompts.js with the following exports:

1. `promptForBatchSelection(proposals)` - Batch selection interface
   - Display options: 'a' (approve all), 'r' (reject all), 's' (select individually)
   - For individual selection: accept comma-separated numbers (e.g., "1,3,5")
   - Return { approved: number[], rejected: number[] } (indices into proposals array)
   - Use readline/promises pattern from lib/prompts.js
   - Handle invalid input gracefully (re-prompt)

2. `promptForRejectionReason(decision)` - Get rejection reason
   - Display decision summary (ID, question, choice)
   - Prompt: "Reason for rejection (optional, press Enter to skip): "
   - Return string (empty string if skipped)

3. `promptForApprovalAction(decision)` - Per-decision action prompt
   - Display decision details
   - Options: 'y' (approve), 'n' (reject), 'e' (edit), 's' (skip for now)
   - Return 'approve' | 'reject' | 'edit' | 'skip'

4. `editDecisionInEditor(decision)` - Open decision in $EDITOR
   - Create .banneker/tmp/ directory if needed
   - Write decision to temp file as JSON with instructional comments:
     ```
     # Edit the decision below (lines starting with # are ignored)
     # Decision ID: DEC-XXX
     # Question: [original question]
     #
     # Save and close to accept changes.
     # To cancel, delete all JSON content.

     {JSON content}
     ```
   - Spawn $EDITOR (or $VISUAL, fallback to 'vi') using child_process.spawn with stdio: 'inherit'
   - Wait for editor to close
   - Read back file, strip comment lines, parse JSON
   - Clean up temp file
   - Return parsed decision (or throw if cancelled/invalid)

Use Node.js built-ins only: readline/promises, fs/promises, child_process, process.
  </action>
  <verify>
Test the module imports correctly:
`node -e "import('./lib/approval-prompts.js').then(m => console.log(Object.keys(m)))"`
Expected: ['promptForBatchSelection', 'promptForRejectionReason', 'promptForApprovalAction', 'editDecisionInEditor']
  </verify>
  <done>
- All four functions exported
- Batch selection handles 'a', 'r', and comma-separated numbers
- Edit workflow creates temp file with comments, spawns editor, parses result
- All use async/await with readline/promises
  </done>
</task>

<task type="auto">
  <name>Task 2: Create banneker-approve.md command orchestrator</name>
  <files>templates/commands/banneker-approve.md</files>
  <action>
Create templates/commands/banneker-approve.md following the pattern from banneker-engineer.md:

YAML Frontmatter:
```yaml
---
name: banneker-approve
description: "Review and approve AI-generated engineering decisions before they merge to architecture-decisions.json"
---
```

Command orchestrator content:

1. **Purpose Section** - Explain this command reviews ENGINEERING-PROPOSAL.md and lets user approve/reject/edit decisions before merge

2. **Input Files**
   - `.banneker/documents/ENGINEERING-PROPOSAL.md` - Contains proposed decisions in ADR format
   - `.banneker/architecture-decisions.json` - Existing decision log (may be empty)

3. **Workflow Steps:**

   Step 1: Load Proposals
   - Read ENGINEERING-PROPOSAL.md
   - Parse ADR blocks (each starts with `# DEC-XXX:`)
   - Extract: id, question, choice, rationale, confidence, alternatives_considered, domain
   - If no proposals found: "No pending proposals. Run /banneker:engineer first."

   Step 2: Display Summary Table
   - Call displayProposalsSummary() from lib/approval-display.js concept
   - Show decisions grouped by domain with confidence indicators
   - Display total count and confidence distribution

   Step 3: Batch Selection
   - Prompt user for batch action (approve all / reject all / select individually)
   - If individual selection: prompt per-decision with approve/reject/edit/skip options

   Step 4: Handle Edits
   - For any decision marked 'edit': open in $EDITOR
   - After edit: ask again (approve/reject the edited version)
   - Track edited decisions separately

   Step 5: Collect Rejection Reasons
   - For each rejected decision: optionally prompt for reason
   - Default reason: "User rejected without reason"

   Step 6: Execute Merge
   - Call mergeApprovedDecisions() for approved decisions
   - Call logRejectedDecisions() for rejected decisions
   - Report: "Merged X decisions, rejected Y decisions"

   Step 7: Update ENGINEERING-PROPOSAL.md
   - Mark approved decisions as "Status: Accepted"
   - Mark rejected decisions as "Status: Rejected (reason: ...)"
   - Keep skipped decisions as "Status: Proposed (awaiting approval)"

4. **Related Commands** - Link to /banneker:engineer

5. **Example Output** - Show sample approval session

Note: The orchestrator describes the workflow for Claude to execute. It does NOT call lib functions directly - Claude reads this as instructions and performs the work using available tools (Read, Write, Bash for editor spawn).
  </action>
  <verify>
1. File exists: `ls templates/commands/banneker-approve.md`
2. Has valid YAML frontmatter: `head -5 templates/commands/banneker-approve.md`
3. Contains workflow steps (grep for "Step")
4. References ENGINEERING-PROPOSAL.md and architecture-decisions.json
  </verify>
  <done>
- Command orchestrator exists with valid frontmatter
- Workflow covers: load proposals, display table, batch selection, edits, rejection reasons, merge, status update
- References correct input/output files
- Follows pattern of other Banneker commands
  </done>
</task>

<task type="auto">
  <name>Task 3: Add approval-prompts.js unit tests</name>
  <files>test/unit/approval-prompts.test.js</files>
  <action>
Create test/unit/approval-prompts.test.js with tests for the approval-prompts module:

```javascript
import { describe, it, beforeEach, afterEach, mock } from 'node:test';
import assert from 'node:assert';
import { mkdir, writeFile, readFile, rm } from 'node:fs/promises';
import { existsSync } from 'node:fs';
import { join } from 'node:path';
```

Test Suites:

1. `describe('editDecisionInEditor')`
   - Test: Creates temp directory if missing
   - Test: Writes decision with comment header
   - Test: Parses JSON correctly after removing comments
   - Note: Cannot easily test $EDITOR spawn in unit tests - focus on file handling

2. `describe('promptForBatchSelection helpers')`
   - Test: Parse comma-separated indices correctly ("1,3,5" -> [0,2,4])
   - Test: Handle out-of-range indices (filter them out)
   - Test: Handle non-numeric input gracefully

3. `describe('formatEditableDecision')`
   - If you extract the comment-formatting logic to a testable function
   - Test: Includes instructional comments
   - Test: Includes valid JSON
   - Test: Comment stripping leaves valid JSON

Use the existing test patterns from test/unit/ directory. Focus on pure functions that don't require mocking stdin.
  </action>
  <verify>
Run: `npm test -- --test-name-pattern="approval"`
All tests should pass.
  </verify>
  <done>
- Test file exists at test/unit/approval-prompts.test.js
- Tests cover file formatting and parsing logic
- Tests pass when run with npm test
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `ls lib/approval-prompts.js templates/commands/banneker-approve.md test/unit/approval-prompts.test.js`
2. `npm test` passes (including new tests)
3. Command orchestrator has valid YAML frontmatter
4. All exports are accessible from lib/approval-prompts.js
</verification>

<success_criteria>
- [ ] lib/approval-prompts.js exports all four functions
- [ ] editDecisionInEditor creates temp file with comments and spawns $EDITOR
- [ ] promptForBatchSelection returns { approved, rejected } arrays
- [ ] templates/commands/banneker-approve.md exists with complete workflow
- [ ] Workflow covers all APPROVE requirements (01, 02, 03)
- [ ] Unit tests pass for approval-prompts module
</success_criteria>

<output>
After completion, create `.planning/phases/13-approval-flow/13-02-SUMMARY.md`
</output>
