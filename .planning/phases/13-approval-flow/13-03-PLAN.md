---
phase: 13-approval-flow
plan: 03
type: execute
wave: 3
depends_on: ["13-02"]
files_modified:
  - test/integration/installer.test.js
  - test/integration/approval.test.js
autonomous: true

must_haves:
  truths:
    - "Installer copies banneker-approve.md to commands directory"
    - "Integration tests verify end-to-end approval workflow"
    - "All tests pass (npm test)"
  artifacts:
    - path: "test/integration/installer.test.js"
      provides: "Installer tests for approve command"
      contains: "banneker-approve"
    - path: "test/integration/approval.test.js"
      provides: "End-to-end approval workflow tests"
      contains: "mergeApprovedDecisions"
  key_links:
    - from: "test/integration/installer.test.js"
      to: "templates/commands/banneker-approve.md"
      via: "cpSync verification"
      pattern: "banneker-approve\\.md"
    - from: "test/integration/approval.test.js"
      to: "lib/approval.js"
      via: "import and function calls"
      pattern: "import.*approval"
---

<objective>
Add installer integration tests for the approve command and end-to-end tests for the approval workflow.

Purpose: Verify that the approval command is correctly installed and that the full approval workflow (merge, reject, log) functions correctly with real file I/O.

Output: Updated installer tests and new approval integration tests following established Banneker test patterns.
</objective>

<execution_context>
@/home/daniel/.claude/get-shit-done/workflows/execute-plan.md
@/home/daniel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-approval-flow/13-01-SUMMARY.md
@.planning/phases/13-approval-flow/13-02-SUMMARY.md

# Test patterns to follow
@test/integration/installer.test.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add installer tests for approve command</name>
  <files>test/integration/installer.test.js</files>
  <action>
Add a new test suite to test/integration/installer.test.js for the approve command installation, following the existing pattern from engineer tests:

```javascript
describe('Approve command installation', () => {
    const tmpDir = join(tmpdir(), 'banneker-test-approve-' + Date.now());
    const commandsDir = join(tmpDir, 'commands');

    beforeEach(async () => {
        await mkdir(commandsDir, { recursive: true });
    });

    afterEach(async () => {
        await rm(tmpDir, { recursive: true, force: true });
    });

    it('should copy banneker-approve.md to commands directory', async () => {
        // cpSync from templates/commands to temp commands dir
        cpSync(join(PACKAGE_ROOT, 'templates', 'commands'), commandsDir, { recursive: true });

        const approveFile = join(commandsDir, 'banneker-approve.md');
        assert.ok(existsSync(approveFile), 'banneker-approve.md should exist');
    });

    it('should contain valid YAML frontmatter', async () => {
        cpSync(join(PACKAGE_ROOT, 'templates', 'commands'), commandsDir, { recursive: true });

        const approveFile = join(commandsDir, 'banneker-approve.md');
        const content = await readFile(approveFile, 'utf8');

        // Check frontmatter structure
        assert.ok(content.startsWith('---'), 'Should start with YAML frontmatter');
        assert.ok(content.includes('name: banneker-approve'), 'Should have correct name');
        assert.ok(content.includes('description:'), 'Should have description');
    });
});
```

Place this test suite near the existing "Engineer command installation" tests for consistency.
  </action>
  <verify>
Run: `npm test -- --test-name-pattern="Approve command installation"`
Both tests should pass.
  </verify>
  <done>
- Test suite added to installer.test.js
- Tests verify file exists after copy
- Tests verify YAML frontmatter is valid
- Tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create approval workflow integration tests</name>
  <files>test/integration/approval.test.js</files>
  <action>
Create test/integration/approval.test.js with end-to-end tests for the approval workflow:

```javascript
import { describe, it, beforeEach, afterEach } from 'node:test';
import assert from 'node:assert';
import { mkdir, writeFile, readFile, rm } from 'node:fs/promises';
import { existsSync } from 'node:fs';
import { join } from 'node:path';
import { tmpdir } from 'node:os';
```

Test Suites:

1. `describe('mergeApprovedDecisions')`
   - Test: Creates architecture-decisions.json if missing
   - Test: Appends to existing decisions array
   - Test: Updates recorded_at timestamp
   - Test: Backup file is created and removed on success
   - Test: Returns count of merged decisions

2. `describe('logRejectedDecisions')`
   - Test: Creates rejection-log.json if missing
   - Test: Appends rejection with timestamp, id, question, choice, reason, full_decision
   - Test: Handles multiple rejections in one call
   - Test: Default reason is used when none provided

3. `describe('displayProposalsSummary')`
   - Test: Groups proposals by domain
   - Test: Handles empty proposals array
   - Test: Truncates long text (mock process.stdout.columns)

Setup pattern for each test:
- Create temp .banneker directory
- Initialize test data (proposals, existing decisions)
- Call function under test
- Assert file contents
- Clean up temp directory

Important: These tests use real file I/O in a temp directory, not mocks. This verifies the actual behavior.
  </action>
  <verify>
Run: `npm test -- --test-name-pattern="mergeApprovedDecisions|logRejectedDecisions|displayProposalsSummary"`
All tests should pass.
  </verify>
  <done>
- Integration test file exists
- Tests cover mergeApprovedDecisions with file creation, append, backup
- Tests cover logRejectedDecisions with all required fields
- Tests cover displayProposalsSummary grouping
- All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 3: Run full test suite and verify all pass</name>
  <files>package.json</files>
  <action>
Run the complete test suite to verify all existing tests still pass and new tests are included:

1. Run: `npm test`
2. Verify all tests pass (0 failures)
3. Check test count has increased from baseline

If any tests fail:
- Fix the failing tests or the code they test
- Do NOT skip or delete existing tests
- Document any changes needed in the summary

Expected outcome: All tests pass, including:
- Existing installer tests
- New approve command installation tests
- New approval workflow integration tests
- Existing unit tests
  </action>
  <verify>
`npm test` exits with code 0 and shows all tests passing.
  </verify>
  <done>
- Full test suite passes
- No regressions in existing tests
- New test files are discovered and run
- Test count increased from baseline
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `npm test` passes with 0 failures
2. `ls test/integration/approval.test.js` shows new test file
3. `grep -c "banneker-approve" test/integration/installer.test.js` shows tests exist
4. Test output shows approval-related tests running
</verification>

<success_criteria>
- [ ] Installer tests verify banneker-approve.md is copied correctly
- [ ] Integration tests verify mergeApprovedDecisions creates/updates architecture-decisions.json
- [ ] Integration tests verify logRejectedDecisions creates/updates rejection-log.json
- [ ] Integration tests verify displayProposalsSummary groups by domain
- [ ] Full test suite passes (npm test exits 0)
- [ ] No regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/13-approval-flow/13-03-SUMMARY.md`
</output>
